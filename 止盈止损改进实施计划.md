# 止盈止损计算改进 - 完整实施计划

## 目标
准确计算止盈止损，通过存储每日价格数据，按时间顺序判断哪个先触发。

## 实施步骤

### 阶段1：数据库结构改造

#### 1.1 创建新表 `stock_signal_daily_prices`
**文件**：`Spiders/spiders/stock_kline.py`  
**方法**：`create_table()`

**表结构**：
```sql
CREATE TABLE IF NOT EXISTS stock_signal_daily_prices (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    signal_id INTEGER NOT NULL,           -- 关联 stock_signals.id
    stock_code TEXT NOT NULL,             -- 股票代码
    date TEXT NOT NULL,                    -- 日期 (YYYY-MM-DD)
    open REAL,                             -- 开盘价
    high REAL,                             -- 最高价
    low REAL,                              -- 最低价
    close REAL,                            -- 收盘价
    days_from_signal INTEGER NOT NULL,     -- 距离信号产生的天数（0表示当天）
    created_at TEXT,                       -- 创建时间
    FOREIGN KEY (signal_id) REFERENCES stock_signals(id),
    UNIQUE(signal_id, date)
)
CREATE INDEX idx_signal_daily_prices_signal_id ON stock_signal_daily_prices(signal_id);
CREATE INDEX idx_signal_daily_prices_stock_code ON stock_signal_daily_prices(stock_code);
CREATE INDEX idx_signal_daily_prices_date ON stock_signal_daily_prices(date);
```

**实施要点**：
- 在 `create_table()` 方法中添加新表创建逻辑
- 添加索引提升查询性能
- 使用 `UNIQUE(signal_id, date)` 防止重复数据

---

### 阶段2：爬虫代码改造

#### 2.1 修改 `update_price_extremes` 方法
**文件**：`Spiders/spiders/stock_kline.py`  
**方法**：`update_price_extremes()`

**修改内容**：
1. 在计算最高价和最低价的同时，保存每日价格数据
2. 遍历 `future_data` 的每一天，保存到 `stock_signal_daily_prices` 表
3. 计算 `days_from_signal`（距离信号产生的天数）

**代码逻辑**：
```python
# 在更新 stock_signals 表之前，先保存每日价格数据
for idx, (date, row) in enumerate(future_data.iterrows()):
    days_from_signal = idx  # 0表示当天，1表示第二天，以此类推
    
    # 删除旧数据（如果存在）
    self.cursor.execute('''
        DELETE FROM stock_signal_daily_prices
        WHERE signal_id=? AND date=?
    ''', (record_id, date.strftime("%Y-%m-%d")))
    
    # 插入新数据
    self.cursor.execute('''
        INSERT INTO stock_signal_daily_prices (
            signal_id, stock_code, date, open, high, low, close,
            days_from_signal, created_at
        )
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        record_id,
        stock_code,
        date.strftime("%Y-%m-%d"),
        round(row.get('open', 0), 2) if pd.notna(row.get('open')) else None,
        round(row.get('high', 0), 2) if pd.notna(row.get('high')) else None,
        round(row.get('low', 0), 2) if pd.notna(row.get('low')) else None,
        round(row.get('close', 0), 2) if pd.notna(row.get('close')) else None,
        days_from_signal,
        datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    ))
```

**注意事项**：
- 使用 `DELETE` + `INSERT` 确保数据幂等性（重复运行不会产生重复数据）
- 处理 `None` 值，避免数据库错误
- 确保日期格式统一为 `YYYY-MM-DD`

---

### 阶段3：后端API改造

#### 3.1 添加获取每日价格数据的API
**文件**：`Spiders/web/app.py`  
**路由**：`/api/signal-daily-prices`

**功能**：
- 根据 `signal_id` 或 `stock_code` + `insert_date` 查询每日价格数据
- 返回按日期排序的价格列表

**API设计**：
```python
@app.route('/api/signal-daily-prices')
def get_signal_daily_prices():
    signal_id = request.args.get('signal_id', type=int)
    stock_code = request.args.get('stock_code', '')
    insert_date = request.args.get('insert_date', '')
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    query = """
        SELECT date, open, high, low, close, days_from_signal
        FROM stock_signal_daily_prices
        WHERE 1=1
    """
    params = []
    
    if signal_id:
        query += " AND signal_id = ?"
        params.append(signal_id)
    elif stock_code and insert_date:
        # 通过 stock_code 和 insert_date 查找 signal_id
        query = """
            SELECT p.date, p.open, p.high, p.low, p.close, p.days_from_signal
            FROM stock_signal_daily_prices p
            JOIN stock_signals s ON p.signal_id = s.id
            WHERE s.stock_code = ? AND s.insert_date = ?
            ORDER BY p.days_from_signal ASC
        """
        params = [stock_code, insert_date]
    else:
        return jsonify({'error': '需要提供 signal_id 或 (stock_code + insert_date)'}), 400
    
    cursor.execute(query, params)
    rows = cursor.fetchall()
    
    prices = []
    for row in rows:
        prices.append({
            'date': row[0],
            'open': row[1],
            'high': row[2],
            'low': row[3],
            'close': row[4],
            'days_from_signal': row[5]
        })
    
    conn.close()
    return jsonify({'prices': prices})
```

---

### 阶段4：前端计算逻辑改造

#### 4.1 修改 `calculateProfitForStock` 函数
**文件**：`Spiders/web/static/js/calendar.js`  
**函数**：`calculateProfitForStock()`

**新逻辑**：
1. 如果记录中有每日价格数据，使用每日价格数据计算
2. 按时间顺序遍历每日价格
3. 检查每天的最高价和最低价是否触及止盈/止损
4. 哪个先触及，就按哪个计算

**实现方案A：前端预加载数据（推荐）**
- 在加载事件列表时，同时加载每日价格数据
- 将每日价格数据附加到事件对象中
- 计算时直接使用内存中的数据

**实现方案B：按需加载数据**
- 计算时，如果发现没有每日价格数据，调用API获取
- 缓存数据，避免重复请求

**代码逻辑**（方案A）：
```javascript
function calculateProfitForStock(rec, profitTarget, stopLoss) {
    if (!rec.buyPrice) return null;
    
    const buyPrice = rec.buyPrice;
    const profitPrice = buyPrice * (1 + profitTarget / 100);
    const lossPrice = buyPrice * (1 + stopLoss / 100);
    
    // 如果有每日价格数据，使用每日价格数据计算
    if (rec.dailyPrices && rec.dailyPrices.length > 0) {
        for (let i = 0; i < rec.dailyPrices.length; i++) {
            const dayData = rec.dailyPrices[i];
            const high = dayData.high;
            const low = dayData.low;
            
            // 检查是否触及止盈
            const hitProfit = high && high >= profitPrice;
            // 检查是否触及止损
            const hitLoss = low && low <= lossPrice;
            
            if (hitProfit && hitLoss) {
                // 如果同一天都触及，需要判断哪个先触发
                // 这里简化处理：如果开盘价更接近哪个目标，就按哪个计算
                const openPrice = dayData.open || buyPrice;
                const profitDistance = Math.abs(openPrice - profitPrice);
                const lossDistance = Math.abs(openPrice - lossPrice);
                
                if (profitDistance <= lossDistance) {
                    // 先触发止盈
                    return { profit: profitTarget, days: dayData.days_from_signal, type: "profit" };
                } else {
                    // 先触发止损
                    return { profit: stopLoss, days: dayData.days_from_signal, type: "loss" };
                }
            } else if (hitProfit) {
                // 只触及止盈
                return { profit: profitTarget, days: dayData.days_from_signal, type: "profit" };
            } else if (hitLoss) {
                // 只触及止损
                return { profit: stopLoss, days: dayData.days_from_signal, type: "loss" };
            }
        }
        // 如果遍历完所有天数都没有触及，返回null
        return null;
    } else {
        // 如果没有每日价格数据，使用旧逻辑（向后兼容）
        const highPrice = rec.highPrice;
        const lowPrice = rec.lowPrice;
        const highDays = rec.highDays || 999999;
        const lowDays = rec.lowDays || 999999;
        
        const canReachProfit = highPrice && highPrice >= profitPrice;
        const canReachLoss = lowPrice && lowPrice <= lossPrice;
        
        if (!canReachProfit && !canReachLoss) {
            return null;
        }
        
        let firstHit = null;
        let firstHitDays = 999999;
        
        if (canReachProfit && highDays < firstHitDays) {
            firstHit = "profit";
            firstHitDays = highDays;
        }
        if (canReachLoss && lowDays < firstHitDays) {
            firstHit = "loss";
            firstHitDays = lowDays;
        }
        
        if (firstHit === "profit") {
            return { profit: profitTarget, days: firstHitDays, type: "profit" };
        } else if (firstHit === "loss") {
            return { profit: stopLoss, days: firstHitDays, type: "loss" };
        }
        return null;
    }
}
```

#### 4.2 修改事件加载逻辑
**文件**：`Spiders/web/static/js/calendar.js`  
**函数**：加载事件列表的地方（可能在 `loadCalendarEvents` 或类似函数）

**修改内容**：
- 在加载事件列表后，批量加载每日价格数据
- 将每日价格数据附加到事件对象中

**代码逻辑**：
```javascript
// 加载事件列表后
async function loadEventsWithDailyPrices() {
    const events = await fetch('/api/calendar/events?...').then(r => r.json());
    
    // 批量加载每日价格数据
    const signalIds = events.map(e => e.id).filter(id => id);
    
    if (signalIds.length > 0) {
        // 可以分批加载，避免一次性请求太多数据
        const dailyPricesMap = await loadDailyPricesBatch(signalIds);
        
        // 将每日价格数据附加到事件对象
        events.forEach(event => {
            if (event.id && dailyPricesMap[event.id]) {
                event.dailyPrices = dailyPricesMap[event.id];
            }
        });
    }
    
    return events;
}

async function loadDailyPricesBatch(signalIds) {
    // 分批加载，每批50个
    const batchSize = 50;
    const result = {};
    
    for (let i = 0; i < signalIds.length; i += batchSize) {
        const batch = signalIds.slice(i, i + batchSize);
        const promises = batch.map(id => 
            fetch(`/api/signal-daily-prices?signal_id=${id}`)
                .then(r => r.json())
                .then(data => ({ id, prices: data.prices }))
        );
        
        const batchResults = await Promise.all(promises);
        batchResults.forEach(({ id, prices }) => {
            result[id] = prices;
        });
    }
    
    return result;
}
```

---

### 阶段5：数据迁移和补充

#### 5.1 创建数据补充脚本
**文件**：`backfill_daily_prices.py`（新建）

**功能**：
- 为现有数据库中的历史信号补充每日价格数据
- 批量处理所有缺少每日价格数据的信号记录

**实施策略**：
1. **查询所有缺少每日价格数据的信号**
   - 查询 `stock_signals` 表中所有记录
   - 检查对应的 `stock_signal_daily_prices` 表是否有数据
   - 筛选出需要补充的记录

2. **批量获取K线数据**
   - 按股票代码分组，批量获取K线数据
   - 使用爬虫的现有逻辑获取历史K线数据

3. **填充每日价格数据**
   - 对每个信号，计算信号产生后30天的每日价格
   - 保存到 `stock_signal_daily_prices` 表

**脚本结构**：
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
补充现有数据库中信号的每日价格数据
"""

import sqlite3
import pandas as pd
from datetime import datetime, timedelta
import sys
import os

# 添加项目路径
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from Spiders.spiders.stock_kline import StockKlineSpider
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings

DB_PATH = os.path.join(os.path.dirname(__file__), 'stock_signals.db')

def get_signals_without_daily_prices():
    """获取所有缺少每日价格数据的信号"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # 查询所有信号，检查是否有对应的每日价格数据
    cursor.execute('''
        SELECT s.id, s.stock_code, s.stock_name, s.insert_date, s.insert_price
        FROM stock_signals s
        LEFT JOIN stock_signal_daily_prices p ON s.id = p.signal_id
        WHERE p.id IS NULL
        ORDER BY s.insert_date DESC
    ''')
    
    signals = cursor.fetchall()
    conn.close()
    
    return signals

def backfill_daily_prices_for_signal(signal_id, stock_code, stock_name, insert_date, insert_price, df):
    """为单个信号补充每日价格数据"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        # 确保DataFrame的索引是datetime类型
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)
        
        # 找到最接近的交易日
        insert_date = pd.to_datetime(insert_date)
        if isinstance(insert_date, str):
            insert_date = pd.to_datetime(insert_date)
        
        # 找到insert_date当天或之后的第一天
        future_dates = df.index[df.index >= insert_date]
        if len(future_dates) == 0:
            print(f"  警告: 信号ID {signal_id} 没有找到insert_date之后的数据")
            return False
        
        nearest_date = future_dates[0]
        created_idx = df.index.get_loc(nearest_date)
        
        # 获取从nearest_date当天到后续30天的数据
        future_data = df.iloc[created_idx:created_idx + 31]
        
        if future_data.empty:
            print(f"  警告: 信号ID {signal_id} 没有未来数据")
            return False
        
        # 确保close列中没有None值
        future_data = future_data[future_data['close'].notna()]
        
        if future_data.empty:
            print(f"  警告: 信号ID {signal_id} 没有有效的收盘价数据")
            return False
        
        # 保存每日价格数据
        saved_count = 0
        for idx, (date, row) in enumerate(future_data.iterrows()):
            days_from_signal = idx
            
            # 删除旧数据（如果存在）
            cursor.execute('''
                DELETE FROM stock_signal_daily_prices
                WHERE signal_id=? AND date=?
            ''', (signal_id, date.strftime("%Y-%m-%d")))
            
            # 插入新数据
            cursor.execute('''
                INSERT INTO stock_signal_daily_prices (
                    signal_id, stock_code, date, open, high, low, close,
                    days_from_signal, created_at
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                signal_id,
                stock_code,
                date.strftime("%Y-%m-%d"),
                round(row.get('open', 0), 2) if pd.notna(row.get('open')) else None,
                round(row.get('high', 0), 2) if pd.notna(row.get('high')) else None,
                round(row.get('low', 0), 2) if pd.notna(row.get('low')) else None,
                round(row.get('close', 0), 2) if pd.notna(row.get('close')) else None,
                days_from_signal,
                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            ))
            saved_count += 1
        
        conn.commit()
        print(f"  ✓ 信号ID {signal_id} ({stock_code}): 保存了 {saved_count} 天的价格数据")
        return True
        
    except Exception as e:
        print(f"  ✗ 信号ID {signal_id} 处理失败: {str(e)}")
        conn.rollback()
        return False
    finally:
        conn.close()

def fetch_kline_data(stock_code, start_date=None, end_date=None):
    """获取股票的K线数据"""
    # 这里可以使用爬虫的现有逻辑
    # 或者直接调用API获取数据
    # 为了简化，这里使用爬虫的逻辑
    
    settings = get_project_settings()
    process = CrawlerProcess(settings)
    
    # 创建爬虫实例
    spider = StockKlineSpider(
        stock_codes=[stock_code],
        start_date=start_date,
        end_date=end_date,
        calc_indicators=False  # 不需要计算指标
    )
    
    # 运行爬虫获取数据
    # 注意：这里需要修改爬虫，使其返回DataFrame而不是保存到数据库
    # 或者直接从爬虫的parse方法中提取数据
    
    # 简化版本：直接调用爬虫的API获取数据
    # 实际实现需要根据爬虫的具体逻辑调整
    
    return None  # 占位符，需要实际实现

def main():
    """主函数"""
    print("=" * 80)
    print("开始补充现有数据库中的每日价格数据")
    print("=" * 80)
    
    # 获取所有缺少每日价格数据的信号
    signals = get_signals_without_daily_prices()
    
    if not signals:
        print("所有信号都已包含每日价格数据，无需补充")
        return
    
    print(f"\n找到 {len(signals)} 个需要补充的信号")
    
    # 按股票代码分组，批量处理
    signals_by_stock = {}
    for signal in signals:
        signal_id, stock_code, stock_name, insert_date, insert_price = signal
        if stock_code not in signals_by_stock:
            signals_by_stock[stock_code] = []
        signals_by_stock[stock_code].append({
            'id': signal_id,
            'stock_name': stock_name,
            'insert_date': insert_date,
            'insert_price': insert_price
        })
    
    print(f"涉及 {len(signals_by_stock)} 只股票\n")
    
    # 处理每只股票
    total_processed = 0
    total_failed = 0
    
    for stock_code, stock_signals in signals_by_stock.items():
        print(f"处理股票: {stock_code} ({stock_signals[0]['stock_name']})")
        print(f"  需要处理 {len(stock_signals)} 个信号")
        
        # 获取该股票的最早和最新信号日期
        dates = [s['insert_date'] for s in stock_signals]
        min_date = min(dates)
        max_date = max(dates)
        
        # 计算需要获取的日期范围（信号日期前1天到信号日期后30天）
        start_date = (pd.to_datetime(min_date) - timedelta(days=1)).strftime("%Y-%m-%d")
        end_date = (pd.to_datetime(max_date) + timedelta(days=30)).strftime("%Y-%m-%d")
        
        # 获取K线数据
        print(f"  获取K线数据: {start_date} 到 {end_date}")
        df = fetch_kline_data(stock_code, start_date, end_date)
        
        if df is None or df.empty:
            print(f"  ✗ 无法获取 {stock_code} 的K线数据，跳过")
            total_failed += len(stock_signals)
            continue
        
        # 处理每个信号
        for signal in stock_signals:
            success = backfill_daily_prices_for_signal(
                signal['id'],
                stock_code,
                signal['stock_name'],
                signal['insert_date'],
                signal['insert_price'],
                df
            )
            
            if success:
                total_processed += 1
            else:
                total_failed += 1
        
        print()
    
    print("=" * 80)
    print(f"补充完成！")
    print(f"  成功: {total_processed} 个信号")
    print(f"  失败: {total_failed} 个信号")
    print("=" * 80)

if __name__ == "__main__":
    main()
```

#### 5.2 优化补充脚本（使用爬虫现有逻辑）

**改进方案**：
- 直接使用 `StockKlineSpider` 的 `update_price_extremes` 方法
- 但需要修改该方法，使其能够：
  1. 接受外部传入的DataFrame
  2. 处理指定的信号ID列表
  3. 只保存每日价格数据，不更新其他字段

**简化实现**：
```python
# 在 stock_kline.py 中添加新方法
def backfill_daily_prices_for_signals(self, signal_ids, df):
    """为指定的信号ID列表补充每日价格数据"""
    # 查询这些信号的基本信息
    placeholders = ','.join(['?'] * len(signal_ids))
    self.cursor.execute(f'''
        SELECT id, stock_code, insert_price, insert_date
        FROM stock_signals 
        WHERE id IN ({placeholders})
    ''', signal_ids)
    
    records = self.cursor.fetchall()
    
    for record_id, stock_code, insert_price, insert_date in records:
        # 使用现有的逻辑保存每日价格数据
        # ...（复用 update_price_extremes 中的逻辑）
```

#### 5.3 运行数据补充脚本

**使用方式**：
```bash
# 补充所有缺少每日价格数据的信号
python backfill_daily_prices.py

# 或者指定股票代码范围
python backfill_daily_prices.py --stock-codes sh600000,sh600001

# 或者指定日期范围
python backfill_daily_prices.py --start-date 2026-01-01 --end-date 2026-01-31
```

**注意事项**：
1. **数据量**：如果历史数据很多，补充可能需要较长时间
2. **API限制**：注意API调用频率限制，可能需要添加延迟
3. **错误处理**：某些股票可能无法获取数据，需要记录并跳过
4. **进度显示**：添加进度条，显示补充进度
5. **断点续传**：支持中断后继续补充，避免重复处理

#### 5.4 验证补充结果

**验证脚本**：
```python
# 检查补充结果
conn = sqlite3.connect(DB_PATH)
cursor = conn.cursor()

# 统计每个信号的价格数据天数
cursor.execute('''
    SELECT s.id, s.stock_code, s.insert_date, COUNT(p.id) as price_days
    FROM stock_signals s
    LEFT JOIN stock_signal_daily_prices p ON s.id = p.signal_id
    GROUP BY s.id
    ORDER BY s.insert_date DESC
''')

results = cursor.fetchall()
for signal_id, stock_code, insert_date, price_days in results:
    if price_days == 0:
        print(f"警告: 信号ID {signal_id} ({stock_code}) 没有每日价格数据")
    elif price_days < 30:
        print(f"提示: 信号ID {signal_id} ({stock_code}) 只有 {price_days} 天的价格数据（可能不足30天）")
```

**建议**：
- 对于新数据，爬虫会自动保存每日价格
- 对于历史数据，运行补充脚本一次性补充
- 可以分批补充，避免一次性处理太多数据

---

### 阶段6：测试验证

#### 6.1 单元测试
- 测试 `calculateProfitForStock` 函数的各种场景
- 测试同一天触及止盈和止损的情况
- 测试没有每日价格数据时的向后兼容性

#### 6.2 集成测试
- 运行爬虫，验证每日价格数据是否正确保存
- 验证API接口返回的数据格式正确
- 验证前端计算逻辑正确

#### 6.3 性能测试
- 测试批量加载每日价格数据的性能
- 优化查询性能（使用索引）

---

## 实施顺序

1. ✅ **阶段1**：创建数据库表（不影响现有功能）
2. ✅ **阶段2**：修改爬虫代码（保存每日价格数据）
3. ✅ **阶段3**：添加后端API（提供数据接口）
4. ✅ **阶段4**：修改前端计算逻辑（使用新数据）
5. ✅ **阶段5**：数据迁移和补充（为现有数据补充每日价格）
   - 5.1 创建数据补充脚本
   - 5.2 优化补充脚本（使用爬虫现有逻辑）
   - 5.3 运行数据补充脚本
   - 5.4 验证补充结果
6. ✅ **阶段6**：测试验证

## 注意事项

1. **向后兼容**：确保没有每日价格数据时，仍能使用旧逻辑计算
2. **性能优化**：批量加载每日价格数据，避免N+1查询问题
3. **数据一致性**：使用事务确保数据一致性
4. **错误处理**：处理数据缺失、API错误等情况
5. **数据量**：每个信号30天的数据，如果信号很多，注意数据库大小

## 预期效果

- ✅ 准确判断止盈止损的触发顺序
- ✅ 准确计算触发天数
- ✅ 支持更复杂的止盈止损策略（如盘中触发）
- ✅ 为未来扩展提供数据基础（如回测、策略优化）
